{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### let's establish connection first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vzD90kyGmPgV"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "from snowflake.snowpark.session import Session\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "connection_parameters = {\n",
        "    \"account\": os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
        "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
        "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
        "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
        "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
        "    \"schema\": os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
        "    \"role\": os.getenv(\"SNOWFLAKE_ROLE\"),\n",
        "}\n",
        "\n",
        "snowpark_session = Session.builder.configs(connection_parameters).create()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### testing the connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLgI7HPinUaa",
        "outputId": "7643567a-e7ad-4557-a3fa-a41094cf5bd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I can't directly view or understand images. However, I can help you with information, answer questions, or provide explanations based on textual descriptions of images. If you describe an image to me, I can certainly assist you with that!\n"
          ]
        }
      ],
      "source": [
        "from snowflake.cortex import Complete\n",
        "\n",
        "print(Complete(\"mistral-large2\", \"can you understand images ?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### building a simple cortex retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ChMH8p3bnn8x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from snowflake.core import Root\n",
        "from typing import List\n",
        "\n",
        "class CortexSearchRetriever:\n",
        "\n",
        "    def __init__(self, snowpark_session: Session, limit_to_retrieve: int = 3):\n",
        "        self._snowpark_session = snowpark_session\n",
        "        self._limit_to_retrieve = limit_to_retrieve\n",
        "\n",
        "    def retrieve(self, query: str) -> List[str]:\n",
        "        root = Root(self._snowpark_session)\n",
        "        cortex_search_service = (\n",
        "            root.databases[os.getenv(\"SNOWFLAKE_DATABASE\")]\n",
        "            .schemas[os.getenv(\"SNOWFLAKE_SCHEMA\")]\n",
        "            .cortex_search_services[\"CC_SEARCH_SERVICE_CS\"]\n",
        "        )\n",
        "        resp = cortex_search_service.search(\n",
        "            query=query,\n",
        "            columns=[\"TEXT_CONTENT\"],\n",
        "            limit=self._limit_to_retrieve,\n",
        "        )\n",
        "\n",
        "        if resp.results:\n",
        "            return [curr[\"TEXT_CONTENT\"] for curr in resp.results]\n",
        "        else:\n",
        "            return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### testing the retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UPNsohTmopxc"
      },
      "outputs": [],
      "source": [
        "retriever = CortexSearchRetriever(snowpark_session=snowpark_session, limit_to_retrieve=4)\n",
        "\n",
        "retrieved_context = retriever.retrieve(query=\"how was my christmas on December 25, 2024?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR7y6HWNoyDh",
        "outputId": "3dd443bc-4946-4e50-abed-ba83af687917"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"this christmas, on December 25, 2024, I had a lot of fun. Me and my family went to watch India vs Australia in BGT on the boxing day, on December 26, 2024.\\nLater at the night on December 26, 2024, we had a couple of meals at McDonald\\'s.\"\\n\\n(Note recorded on Saturday, December 28, 2024 at 05:59 PM)',\n",
              " 'On Tuesday, December 31, 2024, I had an amazing presentation session in my university.\\nI was actually asked to do a paper reading of the \"Attention is All You Need\" paper.\\nI presented the entire thing and was able to give what I had learned to upcoming AI enthusiasts within the university. This kind of events are very helpful for the whole ecosystem.\\n(Note recorded on Tuesday, December 31, 2024 at 05:56 PM)',\n",
              " '\"On Sunday, December 29, 2024, I will be visiting my doctor.\\nAlso, I have a meeting with my team at around 9 PM in the evening on Saturday, December 28, 2024.\\n(Note recorded on Saturday, December 28, 2024 at 06:16 PM)',\n",
              " 'On Tuesday, December 31, 2024, I joined a hackathon and built a product called mindbooklm. The hackathon was the Snowflake RAG and Roll Hackathon. Had a lot of fun collaborating with lots of friends.\\n\\n(Note recorded on Tuesday, December 31, 2024 at 04:47 PM)']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### we see that to retrieve contexts accurately, we need to use exact dates . rather build a function that would standardize our query to actual dates automatically, so that we can query in any reference dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def get_current_date_info():\n",
        "    current = datetime.now()\n",
        "    return {\n",
        "        'date': current.strftime('%Y-%m-%d'),\n",
        "        'day': current.strftime('%A'),\n",
        "        'full_date': current.strftime('%A, %B %d, %Y'),\n",
        "        'time': current.strftime('%I:%M %p')\n",
        "    }\n",
        "def standardize_dates(query):\n",
        "  \n",
        "    current_date = get_current_date_info()\n",
        "  \n",
        "    prompt = f\"\"\"Current date is {current_date['full_date']}.\n",
        "    Convert any relative date references (today, tomorrow, next week, etc.) in this query to actual dates.if there is nothing relative, ignore the date provided, and just provide the query as it is.\n",
        "    Original query: \"{query}\"\n",
        "    Only output the converted query with no explanations or additional text.\"\"\"\n",
        "  \n",
        "    # Make LLM call using existing Snowflake Mixtral integration\n",
        "    response = Complete(\"mistral-large2\", prompt)\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' \"how was my christmas on December 25, 2024?\"'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "standard_query = standardize_dates(\"how was my christmas this year?\")\n",
        "standard_query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### starting trulens session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF8CsPnso15i",
        "outputId": "f4dafda8-8629-4201-dbcf-9508e5f356c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\OneDrive\\Desktop\\snowflake\\myenv\\lib\\site-packages\\trulens\\core\\utils\\imports.py:591: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  return self.imp(name, globals, locals, fromlist, level)\n",
            "Running the TruLens dashboard requires providing a `password` to the `SnowflakeConnector`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦‘ Initialized with db url snowflake://YUBRAJ:***@WPLDZCJ-MINDBOOK/MINDBOOKLM/DATA?role=ACCOUNTADMIN&warehouse=COMPUTE_WH .\n",
            "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n",
            "Error setting TruLens workspace version tag: 000002 (0A000): Unsupported feature 'TAG'., check if you have enterprise version of Snowflake.\n"
          ]
        }
      ],
      "source": [
        "from trulens.core import TruSession\n",
        "from trulens.connectors.snowflake import SnowflakeConnector\n",
        "\n",
        "tru_snowflake_connector = SnowflakeConnector(snowpark_session=snowpark_session)\n",
        "\n",
        "tru_session = TruSession(connector=tru_snowflake_connector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### building simple rag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWPiEGgso_jt",
        "outputId": "7d7658e2-1bc1-4094-ccdf-211c583b1440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decorating <function RAG_from_scratch.retrieve_context at 0x0000012D361C7BE0>\n",
            "decorating <function RAG_from_scratch.generate_completion at 0x0000012D361C7640>\n",
            "decorating <function RAG_from_scratch.query at 0x0000012D361C7760>\n",
            "adding method <class '__main__.RAG_from_scratch'> retrieve_context __main__\n",
            "adding method <class '__main__.RAG_from_scratch'> generate_completion __main__\n",
            "adding method <class '__main__.RAG_from_scratch'> query __main__\n"
          ]
        }
      ],
      "source": [
        "from trulens.apps.custom import instrument\n",
        "\n",
        "\n",
        "class RAG_from_scratch:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.retriever = CortexSearchRetriever(snowpark_session=snowpark_session, limit_to_retrieve=4)\n",
        "\n",
        "    @instrument\n",
        "    def retrieve_context(self, query: str) -> list:\n",
        "        \"\"\"\n",
        "        Retrieve relevant text from vector store.\n",
        "        \"\"\"\n",
        "        return self.retriever.retrieve(query)\n",
        "\n",
        "    @instrument\n",
        "    def generate_completion(self, query: str, context_str: list) -> str:\n",
        "        \"\"\"\n",
        "        Generate answer from context.\n",
        "        \"\"\"\n",
        "        prompt = f\"\"\"You are a personal AI assistant who helps the user recall and elaborate on their past thoughts, plans, and discussions.\n",
        "        You have access to the user's personal notes and memories.\n",
        "\n",
        "        Context of previous discussions:\n",
        "        <context>\n",
        "        {context_str}\n",
        "        </context>\n",
        "\n",
        "        User's current question: {query}\n",
        "\n",
        "        Based on the context and your understanding, provide a helpful and precise response.\n",
        "        If the context directly addresses the question, use those details.\n",
        "        If not, respond based on the most relevant information available.\n",
        "        Always be supportive and sound like a trusted personal assistant.\n",
        "\n",
        "        Respond with a clear, natural text response. Do not use any special formatting or JSON structure.\n",
        "        \"\"\"\n",
        "        return Complete(\"mistral-large2\", prompt)\n",
        "\n",
        "    @instrument\n",
        "    def query(self, query: str) -> str:\n",
        "        context_str = self.retrieve_context(query)\n",
        "        return self.generate_completion(query, context_str)\n",
        "\n",
        "\n",
        "rag = RAG_from_scratch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### to evaluate our app, let's use the rag triad which consists of three evaluation functions i.e context relevance ,groundness and answer relevance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDTFhuNxpb0n",
        "outputId": "1e71d8a4-0148-4763-bdd6-5409319f89e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… In Groundedness, input source will be set to __record__.app.retrieve_context.rets[:].collect() .\n",
            "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
            "âœ… In Context Relevance, input context will be set to __record__.app.retrieve_context.rets[:] .\n",
            "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
          ]
        }
      ],
      "source": [
        "from trulens.providers.cortex.provider import Cortex\n",
        "from trulens.core import Feedback\n",
        "from trulens.core import Select\n",
        "import numpy as np\n",
        "\n",
        "provider = Cortex(\n",
        "    snowpark_session,\n",
        "    model_engine=\"mistral-large2\",\n",
        ")\n",
        "\n",
        "f_groundedness = (\n",
        "    Feedback(provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
        "    .on(Select.RecordCalls.retrieve_context.rets[:].collect())\n",
        "    .on_output()\n",
        ")\n",
        "\n",
        "f_context_relevance = (\n",
        "    Feedback(provider.context_relevance, name=\"Context Relevance\")\n",
        "    .on_input()\n",
        "    .on(Select.RecordCalls.retrieve_context.rets[:])\n",
        "    .aggregate(np.mean)\n",
        ")\n",
        "\n",
        "f_answer_relevance = (\n",
        "    Feedback(provider.relevance, name=\"Answer Relevance\")\n",
        "    .on_input()\n",
        "    .on_output()\n",
        "    .aggregate(np.mean)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTX6HtQVpikc",
        "outputId": "bfb17da9-c89c-409f-84de-387466cf4162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "instrumenting <class '__main__.RAG_from_scratch'> for base <class '__main__.RAG_from_scratch'>\n",
            "\tinstrumenting retrieve_context\n",
            "\tinstrumenting generate_completion\n",
            "\tinstrumenting query\n",
            "skipping base <class 'object'> because of class\n",
            "skipping base <class '__main__.CortexSearchRetriever'> because of class\n",
            "skipping base <class 'object'> because of class\n"
          ]
        }
      ],
      "source": [
        "from trulens.apps.custom import TruCustomApp\n",
        "\n",
        "tru_rag = TruCustomApp(\n",
        "    rag,\n",
        "    app_name=\"memex\",\n",
        "    app_version=\"simple\",\n",
        "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "8Ze4iytMqfZN"
      },
      "outputs": [],
      "source": [
        "prompts = [\"how was my christmas this year ?\", \"how was my last saturday\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "F3fm3RIUqnvV",
        "outputId": "aa6f89b9-ebf9-4813-b1f1-ab063c7b1144"
      },
      "outputs": [],
      "source": [
        "with tru_rag as recording:\n",
        "  for prompt in prompts:\n",
        "        rag.query(prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Groundedness</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_name</th>\n",
              "      <th>app_version</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>memex</th>\n",
              "      <th>simple</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3125</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>4.814703</td>\n",
              "      <td>0.118441</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Answer Relevance  Context Relevance  Groundedness  \\\n",
              "app_name app_version                                                      \n",
              "memex    simple                    1.0             0.3125      0.966667   \n",
              "\n",
              "                       latency  total_cost  \n",
              "app_name app_version                        \n",
              "memex    simple       4.814703    0.118441  "
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tru_session.get_leaderboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### The answer relevancy and groundness scores show that the response from our RAG system is highly relevant to the question and grounded (i.e., no hallucinations). However, the context relevancy score is only 0.3, indicating poor retriever performance. It might be pulling in some unrelated information along with relevant chunks, but the ratio of unrelated content seems to be much higher than the related one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
