{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vzD90kyGmPgV"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "from snowflake.snowpark.session import Session\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "connection_parameters = {\n",
        "    \"account\": os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
        "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
        "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
        "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
        "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
        "    \"schema\": os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
        "    \"role\": os.getenv(\"SNOWFLAKE_ROLE\"),\n",
        "}\n",
        "\n",
        "snowpark_session = Session.builder.configs(connection_parameters).create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "snowpark_session.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLgI7HPinUaa",
        "outputId": "7643567a-e7ad-4557-a3fa-a41094cf5bd0"
      },
      "outputs": [],
      "source": [
        "from snowflake.cortex import Complete\n",
        "\n",
        "print(Complete(\"mistral-large2\", \"can you understand images ?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ChMH8p3bnn8x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from snowflake.core import Root\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class CortexSearchRetriever:\n",
        "\n",
        "    def __init__(self, snowpark_session: Session, limit_to_retrieve: int = 3):\n",
        "        self._snowpark_session = snowpark_session\n",
        "        self._limit_to_retrieve = limit_to_retrieve\n",
        "\n",
        "    def retrieve(self, query: str) -> List[str]:\n",
        "        root = Root(self._snowpark_session)\n",
        "        cortex_search_service = (\n",
        "            root.databases[os.getenv(\"SNOWFLAKE_DATABASE\")]\n",
        "            .schemas[os.getenv(\"SNOWFLAKE_SCHEMA\")]\n",
        "            .cortex_search_services[\"CC_SEARCH_SERVICE_CS\"]\n",
        "        )\n",
        "        resp = cortex_search_service.search(\n",
        "            query=query,\n",
        "            columns=[\"TEXT_CONTENT\"],\n",
        "            limit=self._limit_to_retrieve,\n",
        "        )\n",
        "\n",
        "        if resp.results:\n",
        "            return [curr[\"TEXT_CONTENT\"] for curr in resp.results]\n",
        "        else:\n",
        "            return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UPNsohTmopxc"
      },
      "outputs": [],
      "source": [
        "retriever = CortexSearchRetriever(snowpark_session=snowpark_session, limit_to_retrieve=4)\n",
        "\n",
        "retrieved_context = retriever.retrieve(query=\"how was my christmas on December 25, 2024?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR7y6HWNoyDh",
        "outputId": "3dd443bc-4946-4e50-abed-ba83af687917"
      },
      "outputs": [],
      "source": [
        "retrieved_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF8CsPnso15i",
        "outputId": "f4dafda8-8629-4201-dbcf-9508e5f356c1"
      },
      "outputs": [],
      "source": [
        "from trulens.core import TruSession\n",
        "from trulens.connectors.snowflake import SnowflakeConnector\n",
        "\n",
        "tru_snowflake_connector = SnowflakeConnector(snowpark_session=snowpark_session)\n",
        "\n",
        "tru_session = TruSession(connector=tru_snowflake_connector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWPiEGgso_jt",
        "outputId": "7d7658e2-1bc1-4094-ccdf-211c583b1440"
      },
      "outputs": [],
      "source": [
        "from trulens.apps.custom import instrument\n",
        "\n",
        "\n",
        "class RAG_from_scratch:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.retriever = CortexSearchRetriever(snowpark_session=snowpark_session, limit_to_retrieve=4)\n",
        "\n",
        "    @instrument\n",
        "    def retrieve_context(self, query: str) -> list:\n",
        "        \"\"\"\n",
        "        Retrieve relevant text from vector store.\n",
        "        \"\"\"\n",
        "        return self.retriever.retrieve(query)\n",
        "\n",
        "    @instrument\n",
        "    def generate_completion(self, query: str, context_str: list) -> str:\n",
        "        \"\"\"\n",
        "        Generate answer from context.\n",
        "        \"\"\"\n",
        "        prompt = f\"\"\"You are a personal AI assistant who helps the user recall and elaborate on their past thoughts, plans, and discussions.\n",
        "        You have access to the user's personal notes and memories.\n",
        "\n",
        "        Context of previous discussions:\n",
        "        <context>\n",
        "        {context_str}\n",
        "        </context>\n",
        "\n",
        "        User's current question: {query}\n",
        "\n",
        "        Based on the context and your understanding, provide a helpful and precise response.\n",
        "        If the context directly addresses the question, use those details.\n",
        "        If not, respond based on the most relevant information available.\n",
        "        Always be supportive and sound like a trusted personal assistant.\n",
        "\n",
        "        Respond with a clear, natural text response. Do not use any special formatting or JSON structure.\n",
        "        \"\"\"\n",
        "        return Complete(\"mistral-large2\", prompt)\n",
        "\n",
        "    @instrument\n",
        "    def query(self, query: str) -> str:\n",
        "        context_str = self.retrieve_context(query)\n",
        "        return self.generate_completion(query, context_str)\n",
        "\n",
        "\n",
        "rag = RAG_from_scratch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDTFhuNxpb0n",
        "outputId": "1e71d8a4-0148-4763-bdd6-5409319f89e9"
      },
      "outputs": [],
      "source": [
        "from trulens.providers.cortex.provider import Cortex\n",
        "from trulens.core import Feedback\n",
        "from trulens.core import Select\n",
        "import numpy as np\n",
        "\n",
        "provider = Cortex(\n",
        "    snowpark_session,\n",
        "    model_engine=\"mistral-large2\",\n",
        ")\n",
        "\n",
        "f_groundedness = (\n",
        "    Feedback(provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
        "    .on(Select.RecordCalls.retrieve_context.rets[:].collect())\n",
        "    .on_output()\n",
        ")\n",
        "\n",
        "f_context_relevance = (\n",
        "    Feedback(provider.context_relevance, name=\"Context Relevance\")\n",
        "    .on_input()\n",
        "    .on(Select.RecordCalls.retrieve_context.rets[:])\n",
        "    .aggregate(np.mean)\n",
        ")\n",
        "\n",
        "f_answer_relevance = (\n",
        "    Feedback(provider.relevance, name=\"Answer Relevance\")\n",
        "    .on_input()\n",
        "    .on_output()\n",
        "    .aggregate(np.mean)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTX6HtQVpikc",
        "outputId": "bfb17da9-c89c-409f-84de-387466cf4162"
      },
      "outputs": [],
      "source": [
        "from trulens.apps.custom import TruCustomApp\n",
        "\n",
        "tru_rag = TruCustomApp(\n",
        "    rag,\n",
        "    app_name=\"memex\",\n",
        "    app_version=\"simple\",\n",
        "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8Ze4iytMqfZN"
      },
      "outputs": [],
      "source": [
        "prompts = [\"how was my christmas this year ?\", \"how was my last saturday\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "F3fm3RIUqnvV",
        "outputId": "aa6f89b9-ebf9-4813-b1f1-ab063c7b1144"
      },
      "outputs": [],
      "source": [
        "with tru_rag as recording:\n",
        "  for prompt in prompts:\n",
        "        rag.query(prompt)\n",
        "\n",
        "tru_session.get_leaderboard()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
